BOTTOM HALVES AND DEFERRING WORK -- CHAPTER 8

limitations on interrupt handlers "top half"
	    must not run for too long since they run asynchronously
	    since AT LEAST current interrupt level is disabled, hardware cannot comm. with operating
	    	  system while an interrupt handler runs

	    can't block in interrupt context, so function is limited

bottom halves are necessary to allow interrupt handlers to run quickly and then return to a state where interrupts are enabled

multiple mechanisms for implementing bottom halves

BH -- bottom half -- the first and only method at the time for deferring work in linux
   a bit flag indicated whether bottom half could run
   globally syncronized -- no two could run at same time

Task Queues
     family of queues -- each queue had a linked list of functions
     too inflexible to replace BH entirely
     not lightweight enough for performance-critical routines

2.3 -- introduction of softirqs and tasklets

softirq
	statically defined bottom half that can run simultaneously on multiple processors
	two softirqs of same kind can run simultaneously on different processors
	good for performance

tasklet -- easy to use softirq
	dynamically created
	flexible
	built on top of softirq
	two tasklets of the same type cannot run simultaneously on different processors
	good tradeoff between performance and ease of use

in 2.5 BH and task queue were dropped

now three interfaces exist
    softirq
    tasklet
    work queue

kernel timers -- defer work for specified period of time.


softirq_action is a struct that holds a function that does a softirq action
	       it is a struct so that it can easily be expanded in the future if necessary

softirq_vec holds 32 softirqs, statically allocated

prototype for  a softirq_handler:

void softirq_handler(struct softirq_action *)

can be called like:

my_softirq->action(my_softirq);

softirqs do not preempt another softirq, and the only thing that can preempt a softirq is a hardware interrupt

interrupt handlers usually raise the softirq -- aka mark it for execution
	  the handler then runs at an appropriate time
	  
pending softirqs are checked for at the following places:
	on return from hardware interrupt path
	in ksoftirqd kernel thread
	any code that explicitly checks for pending softirqs

softirq execution occurs in __do_softirq
	this basically calls softirqs in softirq_vec, and borrows the flags of the current process
	     without PF_MEMALLOC
	it proceeds through the pending irqs, bit shifting to nonzero flags, finding a softirq that
	   needs to be called, and then finds locates the appropriate softirq_action, calls it,
	   and loops again

at the time of this book, two subsystems used softirqs directly:
   networking
   block devices

kernel timers and tasklets are built on top of softirqs


must assign a priority to to softirq in an enum in <linux/interrupt.h>

register the softirq via open_softirq
	     
if the same softirq is raised while another is running, proper locking is required
   instead most softirqs resort to per-processor data
   if bottom half doesn't need to scale to inifinite cpus, use a tasklet instead

after registering a softirq with open_softirq(), it can be marked as pending with raise_softirq()

two types of tasklet
    HI_SOFTIRQ
    TASKLET_SOFTIRQ

tasklets are represented by tasklet_struct

main difference from softirq
     only runs on one cpu simultaneously
     serialized with respect to itself
     if intertask sync is necessary, do it with locks, but this only applies when sync is not between two of
     	the same tasklet

difference from old BH
	   different tasklets can run on multiple cpus simultaneously

state can be either 0, TASKLET_STATE_SCHED, or TASKLET_STATE_RUN
      TASKLET_STATE_RUN only used on SMP

count is a reference counter, can only run if 0 and marked pending

scheduled tasklets are the equivalent of raised softirqs, stored in two structures
	  tasklet_vec
	  tasklet_hi_vec
	  both are linked lists

scheduled via tasklet_schedule() or tasklet_hi_schedule()
	  pointer to tasklet_struct as lone argument
	  
tasklet_schedule
{
check the tasklet state and if already running, just return
else call __tasklet_schedule
save irq state
add tasklet to tail of tasklet_vec
set the tail of tasklet_vec to the pointer of t->next (which is null, but can be altered)
"raise" the tasklet
restore interrupt state
}

when a tasklet has been raised, on the next call of do_softirq(), TASKLET_SOFTIRQ or HI_SOFTIRQ is raised
     and tasklet_action() or tasklet_hi_action() handle the processing

tasklet_action
{
disable interrupts
clear tasklet_vec
enable interrupts

iterate all tasklets in tasklet_vec
try to acquire a tasklet lock -- this checks to see if the tasklet is already running
if the preempt count is 0, call tasklet->func(tasklet->data), unlock the tasklet, and call continue

otherwise, a lock wasn't possible so disable irq, set the current task to the end of the tasklet vec
	   __raise_softirq_irqoff(TASKLET_SOFTIRQ), and reenable irqs

}

to statically create a tasklet use DECLARE_TASKLET or DECLARE_TASKLET DISABLED
   note the use of ATOMIC_INIT(0) and ATOMIC_INIT(1)

to dynamically create a tasklet use:
void tasklet_init(struct tasklet_struct *t, tasklet_handler, dev);

where t is a pointer to a dynamically created task struct

tasklets, like softirqs, cannot block
	  they also run with interrupts enabled so be careful to disable interrupts and obtain lock if
	       a tasklet shares data with an interrupt handler
	  also use proper locking 

mark a tasklet as pending:
     tasklet_schedule(&my_tasklet);

a tasklet always runs on the same processor that scheduled it
  makes better use of processor's cache

disable a tasklet:
	tasklet_disable(&my_tasklet)
	if tasklet is currently running, won't return until tasklet stops
	tasklet_disable_nosync() won't wait

enable:
	tasklet_enable(&my_tasklet)

remove from queue:
       tasklet_kill(&my_tasklet)
       this function sleeps, so must not be used from interrupt context

ksoftirqd -- kernel thread to aid in processing of softirqs when system becomes overwhelmed

most softirqs are usually handled on return from handling an interrupt

problem: a balance must be struck between potentially heavy softirq load and userspace
solution: reactivated softirqs (may be reactivated by themselves) are not immediately handled
	  instad, the kernel wakes up a family of kernel threads nice value 19
	  this way userspace isn't starved but softirqs do get run at an appropriate time

one kernel thread per processor
    named ksoftirqd/n where n is the cpu number
    this ensures that if a cpu is free, then it will handle pending softirqs

the gist of a ksoftirqd thread
{
if no softirqs are pending, call schedule
set current state to TASK_RUNNING
while there are softirqs pending
      run softirqs
      if schedule is needed reschedule
sleep
}

old BH
    statically defined with 32 maximum BHs
    modules could not directly use BH interface
    BH handlers were strictly serialized -- not scalable
    task_queues were supposed to replace BH's but never did
    porting from old BH to new softirqs and tasklets was difficult because of weaker serialization
    
deciding between work queues and softirq/tasklets
	 if sleep needed, user work queues, else tasklets

work queues run in process context making them useful for:
     allocating large amounts of memory
     obtain a semaphore
     perform block I/O

work queues are basically an interface for creating kernel threads to handle work queued from elsewhere
     called worker threads
     allow a device driver create a special worker thread to handle deferred work
     called events/n, one per processor
     default worker thread handles work from multiple locations
     
unless a strong need exists for a special worker thread, the default is preferred
       special thread is justifiable when a large amount of work is needed
       	       this has an added benefit of not starving other queued work in default thread

looks like workqueue implementation has changed since Love's book, so I'll try to pull some stuff out of
      the doc

wq allows for asynchronous process execution context
   independent thread serves as the execution context -- worker
   queue of work to do -- work queue
   executes functions associated with work one-by-one









